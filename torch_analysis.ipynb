{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from transformers import BertForSequenceClassification,BertModel\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from utils import CLSdata,CLSdata2\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = \"cpu\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These two codeblocks was used to debug the dataloader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# csv_file = 'src/transformed/data.csv'\n",
    "# npy_dir = 'src/embedded_ef/'\n",
    "\n",
    "# dataset = CLSdata(csv_file=csv_file, npy_dir=npy_dir)\n",
    "# # dataset = SimpleCLSdata(npy_dir=npy_dir)\n",
    "# dataloader = DataLoader(dataset, batch_size=32, num_workers=0,shuffle=True)\n",
    "\n",
    "# Fetch the first item\n",
    "# errorlist = 0\n",
    "\n",
    "# dataset.__getitem__(0)\n",
    "\n",
    "# for i in range(0,100000,5):\n",
    "#     try:\n",
    "#         dataset.__getitem__(i)\n",
    "#     except:\n",
    "#         errorlist +=1\n",
    "# print(f\"{errorlist}/{1000000/5}\")\n",
    "# embed, label = dataset.__getitem__(1000)\n",
    "# print(f\"Embedding shape: {embed.shape}, Label: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "l = []\n",
    "\n",
    "for i in range(20):\n",
    "    l.append(np.load(f\"data/embedded/embedded_text{i}.npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "del l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = 'data/transformed/data.csv'\n",
    "npy_dir = 'data/embedded/'\n",
    "\n",
    "dataset = CLSdata2(csv_file=csv_file, npy_dir=npy_dir)\n",
    "\n",
    "\n",
    "\n",
    "# for i in tqdm(range(len(dataset))):\n",
    "#     dataset[i]\n",
    "# data_loader = DataLoader(dataset, batch_size=1, shuffle=False, num_workers=1)\n",
    "\n",
    "\n",
    "# for i in tqdm(data_loader,colour=\"red\"):\n",
    "#     pass\n",
    "# for i in range(len(dataset)):\n",
    "#     try:\n",
    "#         dataset.__getitem__(i)\n",
    "#     except Exception as e:\n",
    "#         print(\"Index:\",i)\n",
    "#         print(e)\n",
    "\n",
    "# tens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2355961\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We Must split the data first**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8987129813232672\n"
     ]
    }
   ],
   "source": [
    "#Function for simple bootstrap aggregating\n",
    "\n",
    "def bootstrap_samples(labels):\n",
    "    labels_arr = np.array(labels)\n",
    "    \n",
    "    # Get indices of 0 and 1 values\n",
    "    indices_0 = np.where(labels_arr == 0)[0]\n",
    "    indices_1 = np.where(labels_arr == 1)[0]\n",
    "    \n",
    "    # Sample with replacement from 0 values\n",
    "    sampled_indices_0 = np.random.choice(indices_0, size=len(indices_0), replace=True)\n",
    "    \n",
    "    # Sample without replacement from 1 values\n",
    "    sampled_indices_1 = np.random.permutation(indices_1)\n",
    "    \n",
    "    # Combine sampled indices\n",
    "    sampled_indices = np.concatenate([sampled_indices_0, sampled_indices_1])\n",
    "    \n",
    "    # Create the sampled list by selecting items from the original list based on combined sampled indices\n",
    "    sampled_labels = labels_arr[sampled_indices]\n",
    "    \n",
    "    return sampled_labels, sampled_indices\n",
    "\n",
    "\n",
    "labels = np.array(dataset.labels[:-2])\n",
    "indices = np.arange(len(labels))\n",
    "\n",
    "train_idx, temp_idx, train_labels, temp_labels = train_test_split(\n",
    "    indices, labels, test_size=0.4, stratify=labels,shuffle=True,random_state=0)\n",
    "\n",
    "samples = bootstrap_samples(train_labels)\n",
    "print(sum(samples[0])/len(samples[0]))\n",
    "# trainsamples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "labels = np.array(dataset.labels[:-2])\n",
    "indices = np.arange(len(labels))\n",
    "# Assuming X is your features and y is the labels\n",
    "X_train, X_test, y_train, y_test = train_test_split(indices.reshape(-1,1), labels, test_size=0.3, random_state=42)\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "X_test_res, y_test_res = smote.fit_resample(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_res.sum() / len(y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requesting item 1159166\n",
      "Loading new file...\n",
      "Requesting item 403914\n",
      "Loading new file...\n",
      "Requesting item 1308544\n",
      "Loading new file...\n",
      "Requesting item 1396405\n",
      "Requesting item 2122607\n",
      "Loading new file...\n",
      "Requesting item 1028515\n",
      "Loading new file...\n",
      "Requesting item 1104529\n",
      "Requesting item 1313179\n",
      "Requesting item 1012006\n",
      "Requesting item 1520465\n",
      "Loading new file...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jayden\\AppData\\Local\\Temp\\ipykernel_9156\\1006166681.py:3: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  dataset[int(i)]\n",
      "c:\\Users\\Jayden\\Documents\\school\\capstone\\utils.py:122: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ..\\torch\\csrc\\utils\\tensor_numpy.cpp:212.)\n",
      "  embed = torch.from_numpy(self.file_cache[file_idx][local_idx]).float()\n"
     ]
    }
   ],
   "source": [
    "X_train_res\n",
    "for i in X_train_res[:10]:\n",
    "    dataset[int(i)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Basic model with no advanced implementations like dropout or batch norm\n",
    "class Model1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(768,512)\n",
    "        self.layer2 = nn.Linear(512,350)\n",
    "        self.layer3 = nn.Linear(350,300)\n",
    "        self.layer4 = nn.Linear(300,250)\n",
    "        self.layer5 = nn.Linear(250,100)\n",
    "        self.layer6 = nn.Linear(100,2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.layer1(x))\n",
    "        x = F.relu(self.layer2(x))\n",
    "        x = F.relu(self.layer3(x))\n",
    "        x = F.relu(self.layer4(x))\n",
    "        x = F.relu(self.layer5(x))\n",
    "        return self.layer6(x)\n",
    "        # return F.softmax(self.layer6(x),dim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- EPOCH 0 -----\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'train_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 27\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m----- EPOCH \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m -----\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     26\u001b[0m epoch_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m  \u001b[38;5;66;03m# To accumulate loss over the epoch\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, (inputs, labels) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[43mtrain_loader\u001b[49m):\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;28mprint\u001b[39m(labels)\n\u001b[0;32m     29\u001b[0m     inputs, labels \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(device), labels\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_loader' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# Assuming Model1 is defined as per your snippet\n",
    "\n",
    "# Initialize the model\n",
    "model = Model1().to(device)\n",
    "\n",
    "# Define your dataset\n",
    "# Here you should load your dataset and prepare it\n",
    "# For this example, let's assume we have a DataLoader that provides the entire dataset in one batch\n",
    "# trainsubset = Subset(dataset,X_train_res)\n",
    "# testsubset = Subset(dataset,X_test_res)\n",
    "# data_loader = torch.utils.data.DataLoader(trainsubset, batch_size=30000)\n",
    "# Define the loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Initialize the optimizer\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "# Define the number of epochs\n",
    "epochs = 1\n",
    "\n",
    "# Training loop\n",
    "train_loss= []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"----- EPOCH {epoch} -----\")\n",
    "    epoch_loss = 0  # To accumulate loss over the epoch\n",
    "    for idx, (inputs, labels) in enumerate(train_loader):\n",
    "        print(labels)\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs).squeeze()\n",
    "        # print(f\"Labels shape: {outputs.squeeze().shape}, Type: {outputs.dtype}\")\n",
    "\n",
    "        # Compute loss\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Accumulate loss\n",
    "        epoch_loss += loss.item()\n",
    "        print(f\"\\rBatch {idx}, Loss: {loss.item()}\", end = \"\", flush = True)\n",
    "        train_loss.append(loss)\n",
    "    avg_epoch_loss = epoch_loss / len(data_loader)\n",
    "    print(f\"Epoch {epoch+1}, Avg Loss: {avg_epoch_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([*range(1,79+1)],[x.detach().numpy() for x in train_loss])\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "# plt.xticks([*range(1,77+1)])\n",
    "plt.title(\"Loss per \")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(model, data_loader, device):\n",
    "    with torch.no_grad():\n",
    "        model = model.train()\n",
    "        true_pred = 0\n",
    "        tot_samples = 0\n",
    "        for imgs, labels in data_loader:\n",
    "            imgs = imgs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            logits = model(imgs)\n",
    "            _, label_pred = torch.max(logits, axis=1)\n",
    "            true_pred += (label_pred==labels).sum()\n",
    "            tot_samples += labels.shape[0]\n",
    "        acc = (true_pred/float(tot_samples))*100\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Epoch 0 ------\n",
      "Forward Pass\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index out of range in self",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 21\u001b[0m\n\u001b[0;32m     17\u001b[0m inputs, labels \u001b[38;5;241m=\u001b[39m inputs[:, :\u001b[38;5;241m512\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device), labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# inputs, labels = inputs.to(device), labels.to(device)\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlong\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Calculate loss\u001b[39;00m\n\u001b[0;32m     24\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs\u001b[38;5;241m.\u001b[39msqueeze(), labels\u001b[38;5;241m.\u001b[39mfloat())\n",
      "File \u001b[1;32mc:\\Users\\Jayden\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Jayden\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[17], line 13\u001b[0m, in \u001b[0;36mBertClassifier.forward\u001b[1;34m(self, input_ids, attention_mask)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_ids, attention_mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mForward Pass\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 13\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbert\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m     cls_hidden_state \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mlast_hidden_state[:, \u001b[38;5;241m0\u001b[39m, :]  \u001b[38;5;66;03m# Using the hidden state corresponding to [CLS] token\u001b[39;00m\n\u001b[0;32m     15\u001b[0m     linear_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear(cls_hidden_state)\n",
      "File \u001b[1;32mc:\\Users\\Jayden\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Jayden\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Jayden\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:1006\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    999\u001b[0m \u001b[38;5;66;03m# Prepare head mask if needed\u001b[39;00m\n\u001b[0;32m   1000\u001b[0m \u001b[38;5;66;03m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[0;32m   1001\u001b[0m \u001b[38;5;66;03m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[0;32m   1002\u001b[0m \u001b[38;5;66;03m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[0;32m   1003\u001b[0m \u001b[38;5;66;03m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[0;32m   1004\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m-> 1006\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membeddings\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1007\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1008\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1009\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1010\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1011\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1012\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1013\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(\n\u001b[0;32m   1014\u001b[0m     embedding_output,\n\u001b[0;32m   1015\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mextended_attention_mask,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1023\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[0;32m   1024\u001b[0m )\n\u001b[0;32m   1025\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Jayden\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Jayden\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Jayden\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:232\u001b[0m, in \u001b[0;36mBertEmbeddings.forward\u001b[1;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds, past_key_values_length)\u001b[0m\n\u001b[0;32m    229\u001b[0m         token_type_ids \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(input_shape, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mposition_ids\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    231\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inputs_embeds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 232\u001b[0m     inputs_embeds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mword_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    233\u001b[0m token_type_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoken_type_embeddings(token_type_ids)\n\u001b[0;32m    235\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m inputs_embeds \u001b[38;5;241m+\u001b[39m token_type_embeddings\n",
      "File \u001b[1;32mc:\\Users\\Jayden\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Jayden\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Jayden\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\sparse.py:163\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 163\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    165\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Jayden\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\functional.py:2237\u001b[0m, in \u001b[0;36membedding\u001b[1;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[0;32m   2231\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[0;32m   2232\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[0;32m   2233\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[0;32m   2234\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[0;32m   2235\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[0;32m   2236\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[1;32m-> 2237\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mIndexError\u001b[0m: index out of range in self"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(2)\n",
    "random_seed = 1\n",
    "batch_size = 128\n",
    "learning_rate = 0.01\n",
    "num_epochs = 20\n",
    "num_classes = 10\n",
    "\n",
    "\n",
    "model = Model()\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.5)\n",
    "#For storing data on losses\n",
    "train_loss= []\n",
    "\n",
    "start = time.time()\n",
    "for epoch in range(num_epochs):\n",
    "    model = model.train()\n",
    "    for batch_idx, (imgs, labels) in enumerate(trainloader):\n",
    "        imgs = imgs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        ## Forward Propagation - extract features and classify\n",
    "        logits = model(imgs)\n",
    "        loss = F.cross_entropy(logits, labels)\n",
    "        \n",
    "        #zero out the gradients\n",
    "        optimizer.zero_grad()\n",
    "        #estimate new gradients\n",
    "        loss.backward()\n",
    "        #update parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        if not (batch_idx + 1) % 100:\n",
    "            print(\n",
    "                f\"Epoch: {epoch + 1:03d}/{num_epochs:03d} | \"\n",
    "                f\"Batch: {batch_idx + 1:03d}/{len(trainloader):03d} | \"\n",
    "                f\"Loss: {loss:.4f}\"\n",
    "            )\n",
    "    \n",
    "    # Tracking the Learning Rate Scheduler\n",
    "    prev_lr = optimizer.param_groups[0][\"lr\"]\n",
    "    scheduler.step()\n",
    "    current_lr = optimizer.param_groups[0][\"lr\"]\n",
    "    print(f\"Epoch: {epoch+1:03d} Learning Rate {prev_lr:.8f} -> {current_lr:.8f}\")\n",
    "\n",
    "    # Evaluate Performance after each epoch\n",
    "    model = model.eval()\n",
    "    tr_acc = accuracy(model, trainloader, device)\n",
    "    valid_acc = accuracy(model, valid_loader, device)\n",
    "    print(f\"Train Accuracy: {tr_acc:0.3f}\")\n",
    "    print(f\"Validation Accuracy: {valid_acc:0.3f}\")\n",
    "    print(f\"Time elapsed so far: {(time.time() - start) / 60:.2f} min\")\n",
    "    train_loss.append(loss)\n",
    "print(f\"Total Train Time: {(time.time() - start) / 60:.2f} min\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
